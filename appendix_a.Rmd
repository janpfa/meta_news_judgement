# Effect sizes {#effect-sizes}

## Alternative effect sizes

\FloatBarrier  

Table \@ref(tab:effects) shows the estimated SMCC for both discernment (H1) and response bias (H2). For reference, we included the estimates for two alternative estimators: A standardized mean difference assuming independence (SMD), precisely Hedge's g, and a standardized mean change using raw (instead of change) score standardization (SMCR) [@becker1988]. When using raw score standardization, the standardized mean change expresses the effect size in terms of the standard deviation units of the pre-treatment (in our case false news) scores, rather than the standard deviation of the difference scores (involving the correlation) [@becker1988]. While our SMCC depends on the value of the correlation between the false and true news scores, the SMD and the SMCR do not. The interpretation of all three effect measures is similar: all are expressed in terms of standard deviations. Yet, they are different estimators, because they rely on different standard deviations, thereby producing different estimates and standard errors [@morris2002]. Due to the low average correlation between false and true news ratings, the SMCC produces the most conservative (i.e. smallest) effect estimates for both discernment and response bias.

```{r effects, fig.pos='H'}
# main result table
modelsummary::modelsummary(list("Discernment" = robust_model_accuracy, 
                                "Response bias" = robust_model_error,
                                "Discernment" = SMCR_model_accuracy, 
                                "Response bias" = SMCR_model_error,
                                "Discernment" = SMD_model_accuracy, 
                                "Response bias" = SMD_model_error),
                           title = 'Model results', 
                           stars = TRUE, 
                           coef_rename = c("overall" = "Estimate")
                           ) %>%
  add_header_above(c(" " = 1, "SMCC" = 2, "SMCR" = 2, "SMD" = 2)) %>%
  add_header_above(c(" " = 1, "Main estimator (preregistered) " = 2, "Alternative estimators" = 4),
                   line = FALSE, italic = TRUE) %>%
  # make smaller to fit
  kable_styling(latex_options = "scale_down") %>%
  footnote(general = "Comparison of different effect sizes. The SMCC (Standardized mean change using change score standardization) is the estimator we pre-registered and report in the main analysis. For reference, we provide the results we obtain when using a standardized mean difference assuming independence (SMD), precisely Hedge's g, and a standardized change score using raw (instead of change) standardization (SMCR). For effects from studies that used a between participant design, we always calculated Hedge's G, including in those results listed under \"SMCC\" and \"SMCR\"."
           , threeparttable = TRUE)
```

## Sensitivity analysis for imputed correlation

When using *standardized* effect measures, accounting for dependency by imputing correlations impacts the magnitude of the effect estimate itself. That is because, in this case, the standard deviation is not only used to calculate the standard error (as with *non* standardized effects), but also for the effect itself. [Standardized effect measures depending on imputed correlations should therefore be accompanied by a sensitivity analysis](https://training.cochrane.org/handbook/current/chapter-23#section-23-2-7-2), i.e. check how sensitive the effect estimate is to different imputed correlation values [@higgins_cochrane_2019]. Figures \@ref(fig:correlations-discernment) and \@ref(fig:correlations-bias) show that our results hold when imputing any of the other correlation values occurring in the individual-level data. Moreover, all estimates from those imputations yield conservative (i.e. smaller) estimates compared to Hedges' g.
```{r, message = FALSE}
# load individual level subset data and average correlation
individual_level_subset <- read_csv("data/individual_level_subset.csv")

# load correlations
correlations <- read_csv("data/correlations_by_sample.csv") %>% pull(r)
```

```{r}
# function that generates model estimates per each observed correlation 
# in the individual-level data
robustness_correlation_values <- function(correlations, effect) {
  
  results <- correlations %>% 
    # make a loop that for each correlation adds the main effect size in the 
    # mixed meta model to a data frame
    map_df(function(x) {
      
      # Keep track
      print(paste0("Currently estimating model for corrrelation value ", x))
      
      # Step 1: Add correlation to data frame
      raw_data <- meta_wide %>% 
        mutate(cor = x)
      
      # Step 2: Caculate effect data
      data <- calculate_effect_sizes(data = raw_data, effect = effect)
      
      # Step 3: Run model
      model <- calculate_models(data)
      
      # Step 4: Return estimate of interest
      result <- tidy(model) %>% 
        mutate(imputed_correlation = x, 
               effect = effect) %>% 
        mutate_if(is.numeric, round, 5)
      return(result)
      }) 
  
  return(results)
}
```

```{r}
# a function that returns the main average effect assuming *independence*
robustness_independence <- function(effect = "accuracy", measure = "SMD") {
  
  
  # Step 1: Calculate effect data
  data <- calculate_effect_sizes(data = meta_wide, effect = effect, 
                                 measure = measure)
  
  # Step 2: Run model
  model <- calculate_models(data)
  
  # Step 3: Return estimate of interest
  result <- tidy(model) %>% 
    mutate(effect = effect) %>% 
    mutate_if(is.numeric, round, 5)
  
  return(result) 
}
```

```{r}
# write a function that returns plots to compare model results from different imputations of correlations 
# (and a version assuming independence)
robustness_plot <- function(effect){
  
  # set name for plot
  if(str_detect(effect, "accuracy")){
    name <- "Discernment"
  } else { name <- "Response bias"}
  
  # calculate effect as function of correlation value for error
  effect_by_correlation <- robustness_correlation_values(correlations, effect = effect)
  
  # calculate effect assuming independence for error
  effect_independence <- robustness_independence(effect = effect)
  
  # get data and main model results from environment
  main_model_name <- paste0("robust_model_", effect)
  data_name <- paste0(effect, "_effect")
  
  main_model <- get(main_model_name)
  data <- get(data_name)
  
  # get tidy version of main model (to be used as reference)
  main_model <-  tidy(main_model) %>% 
    mutate_if(is.numeric, round, 5) %>% 
    # add the value of the correlation
    mutate(imputed_correlation = mean(data$cor))
  

# plot distribution of standard error
  SE_plot <- ggplot(effect_by_correlation, 
                    aes(x = imputed_correlation, y = std.error,
                        fill = "a", color = "a")) + 
    geom_point(alpha = 0.6) + 
    # add point with average correlation effect
    geom_point(data = main_model, aes(x = imputed_correlation, y = std.error), 
               color = "red", fill = "red")  +
    geom_text(data = main_model, aes(x = imputed_correlation, y = 0.9*std.error, 
                                     label =  paste0("average correlation \n(", round(
                                       imputed_correlation, digits = 2), ")")),
              color = 'red', nudge_x = 0.08, 
              # since we didn't pre-compute means, ggplot would print 
              # mean for each observation which makes the text
              # super bold - so we tell it to check for overlap and remove it
              check_overlap = T
    ) + 
    # add h_line with effect assuming independence
    geom_hline(data = effect_independence, aes(yintercept = std.error), 
               linetype='dotted', 
               color = 'darkorange') +
    geom_text(data = effect_independence, aes(y = 0.95*std.error, x = 0, 
                                              label =  paste0("Hedges'g \n (assuming independence)",
                                                              "\n", "= ", 
                                                              round(std.error, digits = 4))),
              color = 'darkorange', nudge_x =  0.04,
              check_overlap = T
    ) +
    # colors 
    scale_color_viridis_d(option = "plasma") +
    scale_fill_viridis_d(option = "plasma") +
    # labels and scales
    guides(color = "none", fill = "none") +
    labs(x = "Imputed Correlation", y = paste0("Standard Error (", name, ")")) +
    plot_theme

# scatter plot effect by correlation
effect_plot <- ggplot(effect_by_correlation,
                      aes(x = imputed_correlation, y = estimate, 
                                               fill = "a", color = "a")) + 
  geom_point(alpha = 0.6) + 
  # add point with average correlation effect
  geom_point(data = main_model, aes(x = imputed_correlation, y = estimate), 
             color = "red", fill = "red")  +
  geom_text(data = main_model, aes(x = imputed_correlation, y = 0.9*estimate, 
                                     label =  paste0("average correlation \n(", round(
                                       imputed_correlation, digits = 2), ")")),
            color = 'red', nudge_x = 0.08, check_overlap = T) + 
  # add h_line with effect assuming independence
  geom_hline(data = effect_independence, aes(yintercept = estimate), 
             linetype='dotted', 
             color = 'darkorange') +
  geom_text(data = effect_independence, aes(y = 0.95*estimate, x = 0, 
                                                  label =  paste0("Hedges'g \n (assuming independence)",
                                                                  "\n", "= ", 
                                                                  round(estimate, digits = 2))),
            color = 'darkorange', nudge_x =  0.04,
            check_overlap = T
  ) +
  # colors 
  scale_color_viridis_d(option = "plasma") +
  scale_fill_viridis_d(option = "plasma") +
  # labels and scales
  guides(color = "none", fill = "none") +
    labs(x = "Imputed Correlation", y = paste0("SMCC (", name, ")")) +
  plot_theme

return(list(effect_plot, SE_plot))
}  
```

```{r, include=FALSE}
# make plots for accuracy
accuracy_plots <- robustness_plot("accuracy")
```

(ref:correlations-discernment) Estimated effect and standard error for discernment as a function of the imputed correlation value. Each dot represents an estimate corresponding to an imputed correlation value. There is one dot for each observed intra-sample correlation in the individual-level data. For reference, the horizontal dotted lines mark the estimate obtained when using Hedges'g, an effect size assuming independence.  

```{r correlations-discernment, fig.cap="(ref:correlations-discernment)", fig.height= 3}
accuracy_plots[[1]] + accuracy_plots[[2]]
```

(ref:correlations-bias) Estimated effect and standard error for response bias as a function of the imputed correlation value. Each dot represents an estimate corresponding to an imputed correlation value. There is one dot for each observed intra-sample correlation in the individual-level data. For reference, the horizontal dotted lines mark the estimate obtained when using Hedges'g, an effect size assuming independence. 

```{r, include=FALSE}
# make plots for error
error_plots <- robustness_plot("error")
```

```{r correlations-bias, fig.cap="(ref:correlations-bias)", fig.height= 3}
error_plots[[1]] + error_plots[[2]]
```

## Effects on original scales

Table \@ref(tab:scales) shows estimates by scale, in the original units of the scale. The table is intended to help interpret the magnitude of the effect sizes reported in the main findings. Note that some scales occur very rarely only (see Tab. \@ref(tab:n-scales)), hence making their meta-analytic estimates less meaningful.

```{r n-scales}
meta_wide %>% group_by(accuracy_scale) %>% summarise(Papers = n_distinct(paperID),
                                                     Samples = n_distinct(unique_sample_id),
                                                     Effects = n_distinct(observation_id)
                                                     ) %>% 
  mutate(accuracy_scale = ifelse(accuracy_scale == "binary", accuracy_scale, 
                                 paste0(accuracy_scale, "-point"))) %>% 
  pivot_longer(-accuracy_scale,
               names_to = "variable",
               values_to = "frequency"
               ) %>% 
  pivot_wider(names_from = accuracy_scale, 
              values_from = frequency) %>% 
  column_to_rownames(var = "variable") %>% 
  apa_table(note = "Frequency table of scales.")
```

```{r, include=FALSE}
# run models by scale
results_by_scale <- models_by_scale()

# # as data frame
# results_by_scale <- models_by_scale(return_as = "data_frame")
```

```{r scales}
# Extract list elements containing "Accuracy" in the name
accuracy_list <- results_by_scale[grep("Accuracy", names(results_by_scale))]

# Extract list elements containing "Error" in the name
error_list <- results_by_scale[grep("Error", names(results_by_scale))]

# Function to extract number or "binary" from name
extract_number <- function(name) {
  if (grepl("binary", name))
    return("binary")
  
  number <- gsub("\\D", "", name)
  if (number != "")
    return(paste0(number, "-point"))
  
  return(name)
}

# Modify names in accuracy_list
accuracy_list <- setNames(accuracy_list, sapply(names(accuracy_list), extract_number))

# Modify names in error_list
error_list <- setNames(error_list, sapply(names(error_list), extract_number))

# make list of lists
results <- list("Discernment" = accuracy_list, 
                "Response bias" = error_list)


# by scale result table
modelsummary::modelsummary(results,
                           title = '(Raw) Mean Differences between true and false news', 
                           stars = TRUE, 
                           coef_rename = c("overall" = "Estimate"),
                           shape = "rbind"
                           ) %>%
  # make smaller to fit
  kable_styling(latex_options = "scale_down") %>%
  footnote(general = "One scale, a 100-point scale, does not appear since there was only one effect size on that scale")

```




